\chapter{Optimizing network-utilization by balancing workload}
\label{chap:balancing}

The last chapter brings an overview of different notations, algorithms and techniques.
In this chapter, all these instruments are combined to a chain for distributing routes more evenly.
The goal is to augment a given graph, such that diverse alternative paths can be found and used to spread too much load while limiting the detours of individual \glspl{stpair}.
After the theory is explained, implementation-details are discussed.
When talking about performance, it is referred to the used testing-machine, which is an ordinary, but good home-computer.
Further details about the testing-machine and experimental results can be found in \vref{chap:experiments}.

For a given \gls{stpair} and a street-network given as a graph $G = (V, E)$ with vertices $V$, edges $E$ and a cost-function $c: E \to \mathbb{R}_+^d$, that returns a cost-vector for each edge $e \in E$, a path should be found through an algorithm, that implicitly tends to distribute found paths over the network, while keeping the paths' costs sufficiently near every cost-dimension's optimum.
Note, that $\mathbb{R}_+^d$ doesn't contain zero, which would, depending on the metric, result in bad alternative routes otherwise.

To achieve this, a computation-phase called balancing analyzes the graph $G$ and computes a new metric, called workload-metric.
With this workload-metric, routing-algorithms like \gls{repr} and Dijkstra (with personalized routing) can compute paths as usual.
For comparison, multiple scenarios using different combinations of these two routing-algorithms will be used.
Please note, that Dijkstra doesn't guarantee a tolerance when used with personalized routing and hence, some combinations don't provide an upper bound for path-costs.
This will also be pointed out in the respective experiments in \cref{chap:experiments}.

This thesis focusses only on distance and travel-time, where travel-time is the only metric with a provided tolerance.

It should be noted, that Dijkstra (bidirectional) instead of A* is used for every occuring routing-query, may it be in \gls{repr} or anywhere else.
The reason is, that A* works with heuristics, which are difficult to generalize over custom, artificial metrics.
The only benefit from using A* is the reduction of the search-space, which can be reduced much more using bidirectional Dijkstra on graphs contracted via contraction-hierarchies.
Besides that, the graph has multidimensional metrics, for which reason Dijkstra is used with personalized routing.

\section{Balancing to create a new metric}

    This balancing is depicted in \vref{fig:balancing:algorithm} and explained briefly in the caption or detailled in the following.
    It basically runs routing-queries, counts the resulting workload and adjusts a third metric (in addition to travel-distance and travel-time) to influence future query-executions.
    After the new workload-metric will have been settled, routing-algorithms for multidimensional metrics can run queries on the balanced graph $G$ as before, now considering the new workload-metric.
    Therefore, queries will be run in the experiments (\cref{chap:experiments}) to evaluate the new spread of the street-network.
    The set of \glspl{stpair} will be chosen differently than the set used in balancing, to reduce the dependence on it.

    \begin{figure}
        \centering
        \input{resources/graphics/balancing/algorithm}
        \caption[Overview of balancing a graph]{%
            This flow shows the balancing, that analyzes a given graph $G$.
            Here, an evaluation-phase is included afterwards.
            Shapes for actions are rectangular and blue, shapes for data are elliptical and red.
            A new, artificial metric is created for $G$ and gets updated iteratively.
            In the end, this new metric allows a routing-algorithm to distribute upcoming workload (like during rush-hour) more evenly over the underlying street-network in $G$.
            This more spreaded workload can be seen in the evaluation-step, where paths for a set of \glspl{stpair} are searched, once using and once ignoring the new metric.

            Note, that the action doing the path-searches ignores the new metric in the first balancing-iteration.
            \label{fig:balancing:algorithm}
        }
    \end{figure}

    \subsection{Selection of route-pairs}

        Let a street-network be given as a graph $G = (V, E)$ as defined in \cref{chap:preliminaries:graphs}.
        Before such a graph can be balanced, a set of \glspl{stpair} has to be chosen.
        Here, different strategies can be applied.
        For simplicity, the set of \glspl{stpair}, which are used for balancing $G$, might consist of $s$ and $t$ chosen \gls{uar}\ from $V$.
        This has the disadvantage, that a sufficiently large set of \glspl{stpair} is needed to overload $G$.
        This clearly becomes a bottleneck for performance on larger graphs (beginning with small German counties like Saarland with almost $|V| \approx \num{580000}$ and $|E| \approx \num{1160000}$ after parsing), especially when using \gls{repr}, that computes multiple Dijkstra-queries per run.
        To alleviate the computational burden of a large number of \glspl{stpair}, knowledge of the typical workloads in this graph could be used.
        Instead of picking \gls{uar}\ from $|V|$, other distributions could be chosen by weighting $v \in V$ differently or by using some \glspl{stpair} multiple times (on purpose, not only by random).
        For example, real, daily, critical \glspl{stpair} are not distributed \gls{uar}\ over $V$.
        The rush-hour in the morning, when everybody travels from their home to work, is a good counterexample here.
        The set of chosen $t$ might be much smaller than the set of chosen $s$, and less people live near industry or motorways.
        Heuristics as described in~\cite{bakillah:population_from_osm} can return \glspl{stpair} based on approximating population-data from street-networks.
        So considering more specific sets of \glspl{stpair} might be interesting and helpful to boost the balancing up, but is not covered in this thesis.
        The reason for keeping the choice \gls{uar}\ is the easy implementation, while results are sufficiently good enough, as long as $G$ shows differently (over-) loaded streets.

    \subsection{First steps of the balancing-process}
    \label{chap:balancing:balancing}

        At first, the graph $G$, that should be balanced, has to be read in.
        Before continuing, every metric is divided by the respective metric-mean resulting in $G = (V, E)$ of normalized metrics.
        Non-normalized metrics of different scales would cause \gls{repr} to find $\alpha$-values of different scale, making some metrics more important than others just based on their different scales.
        With metrics of different importance, the chosen paths tend to the respective metrics and distort the spread.
        So normalization doesn't just allow to compare different graphs (of different metrics), but also improves the spread in \gls{repr}.

        This graph $G$ is contracted via contraction-hierarchies to $G_{CH}$.
        The step of contracting is not needed for correctness, but reduces the needed runtime (even if $G$ is not being fully contracted).
        For this reason, $G$ instead of $G_{CH}$ is used in the following, to emphasize, that contraction is not necessary from a theoretical point of view.

        Given the \glspl{stpair} and a graph $G$, a path in $G$ is searched for every \gls{stpair}.
        The search may use either Dijkstra or \gls{repr}.
        Multiple paths are found by \gls{repr}, so one of them is chosen \gls{uar}\ after filtering all found paths by a given tolerance.
        Note, that Dijkstra with personalized routing doesn't consider any tolerance.
        But since \gls{repr} calls Dijkstra multiple times, just Dijkstra is faster.
        On the other hand, when using \gls{repr} with choosing a path \gls{uar}, the resulting paths are more spreaded over the network.
        This results in a better coverage of $E$ when updating the workload-metric, which allows the \gls{repr} to find more pareto-optimal personalized routes in the convex hull.
        Both methods are compared in the experiments in \vref{chap:experiments}.

        When using \gls{repr}, the quality of the balanced graph highly depends on the choice of initial paths for \gls{repr}.
        The basic approach in~\cite{barth:alternative_multicriteria_routes} suggests to use $(d+1)$ initial alphas to define one initial convex hull for a graph of $d$-dimensional metrics.
        \begin{equation}
        \label{eq:init_alphas}
        \begin{aligned}
            \left( \alpha^{(1)}, \alpha^{(2)}, \dots, \alpha^{(d)} \right) &= \mathbb{I}^d\\
            \alpha^{(d+1)} &= \left( \frac{1}{d}, \dots, \frac{1}{d} \right)^T
        \end{aligned}
        \end{equation}
        This suggestion is nice to get a tolerance, because every metric's optimal path is computed.
        However, in the balancing, this suggestion needs some adjustment.
        When the new workload-metric is added (hence let the graph's metrics' dimension be $d+1$), $\alpha^{(d+1)}$ becomes $\alpha^{(d+2)}$, which is a different direction in the $(d+1)$-cost-space than the previous $\alpha^{(d+1)}$ points to in the $(d+1)$-cost-space.
        For example (considering only \alpha's direction, not its length), let $d=2$ become $d=3$, hence $\alpha^3=(1, 1) \in \mathbb{R}_+^2$ becomes $\alpha^4=(1, 1, 1) \in \mathbb{R}_+^3$ and respectively $(1, 1, 0) \in \mathbb{R}_+^3$ from the previous case $d=2$ is missing now.
        In the case of Saarland in the experiments, this lead to the issue, that the initially found paths (as suggested in~\cite{barth:alternative_multicriteria_routes}) weren't enough to get an initial convex hull.
        Because of this, less paths have been found on Saarland in the experiments.
        Therefore, the balancing extends the original suggestion by~\cite{barth:alternative_multicriteria_routes} and takes the initial $\alpha^{(j)}$ from $\left\{ 0, 1 \right\}^{(d+1)}$ excluding $(0, \dots, 0)^T$.
        Only the direction of $\alpha$ is relevant, so the previous notation in \cref{eq:init_alphas} can be simplified.
        \begin{equation}
            \label{eq:new_init_alphas}
            \alpha \in \left\{ 0, 1 \right\}^{(d+1)} \setminus \left\{ \left( 0, \dots, 0 \right)^T \right\} \Rightarrow \alpha \text{ is an initial } \alpha^{(j)}
        \end{equation}

        After finding a set of paths for the given \glspl{stpair}, every edge $e \in E$ counts the number of found paths, that contain this edge $e$.
        This workload of balancing-iteration $i$ is normalized by all workloads' mean and the result is used to update the graph's workload-metric.
        \begin{equation}
        \label{eq:workloads}
        \begin{aligned}
            &\mathit{workloads}_{e,i} = \left| \left\{ (s, t) \in \text{\glspl{stpair}} : \text{found path from $s$ to $t$ uses } e \in E \right\} \right|\\
            \Rightarrow\ &\mathit{new}_{e,i} = \frac{\mathit{workloads}_{e,i}}{\mathit{mean}(\mathit{workloads}_i)}
        \end{aligned}
        \end{equation}

    \subsection{Updating the new metric with the collected workload}
    \label{chap:balancing:update}

        Updating the old workload-metric is a very small step in the balancing with a large impact on the ongoing balancing's performance and the quality of the balanced graph.
        Two approaches have been tested and are depicted in the following, after talking about the interpretation of the new artificial workload-metric.

        The workload-metric can be associated with popularity, because it refers to high usage.
        A path of high popularity should be chosen less often than without the workload-metric.
        So, hopefully, updating the workload-metric dependent on the current workload-metric reveals the final, balanced state of the network eventually.
        You could suggest, that a street's capacity should be considered as well, because large streets like motorways can support more vehicles than a street in a city and thus should tolerate a higher popularity than smaller streets.
        A street-capacity could be approximated using a street's number of lanes or the respective street-type (\eg\ motorways) and its length.
        Herewith, the workload-metric, penalizing popularity, would be corrected in favor of larger streets with (usually) higher speed-limit.
        That is exactly contraproductive, because the travel-time does already consider the capacity of streets with the speed-limit.
        In other words, the popularity-penalization should compensate the popularity of larger streets, that have a better travel-time.
        This wished effect would be disturbed by the consideration of capacity.

        The first approach is inspired by a simpler numerical method for solving initial-value-problems called explicit Euler.
        Let $\mathit{old}_i$ be the workload-metric (already normalized after $G$ has been initialized) already stored in the graph and $\mathit{new}_i$ be the new workload-metric (normalized by their mean, see \vref{eq:workloads}).
        \begin{equation}
        \label{eq:euler}
            \mathit{old}_{e,i+1} = \mathit{old}_{e,i} + (\mathit{new}_{e,i} - \mathit{old}_{e,i}) \cdot \mathit{correction}
        \end{equation}
        In each balancing-iteration, after the workload-metric is updated (as in \cref{eq:euler}), every value of the workload-metric smaller than a predefined minimum value $\epsilon$ (\eg\ \num{0.1}) is set to $\epsilon$.
        This removes the metrics of value \num{0.0}, which improves the set of computed shortcuts when applying contraction-hierarchies and thus performance.
        In addition, the result isn't normalized by its mean in general, for which reason it is finally normalized.
        \begin{equation}
        \label{eq:metric_cleanup}
        \begin{aligned}
            \mathit{old}_{e,i+1} &\leftarrow \mathit{max} \left( \epsilon \text{,\ } \mathit{old}_{e,i+1} \right)\\
            \mathit{old}_{e,i+1} &\leftarrow \frac{\mathit{old}_{e,i+1}}{\mathit{mean}(\mathit{old}_{i+1})}
        \end{aligned}
        \end{equation}

        In fact, this approach works okay in smaller, overloaded networks like Isle~of~Man ($|V| \approx \num{50000}$ and $|E| \approx \num{100000}$ after parsing), but lacks in convergence.
        In the first update-iteration, popular paths are ignored as much as possible, before they are highly preferred in the second iteration, ignored in the third iteration and so on.
        This behaviour could be reduced by adding the $\mathit{correction}$, but larger networks (like the small German county Saarland, $|V| \approx \num{580000}$ and $|E| \approx \num{1160000}$ after parsing) worsen the convergence.
        Further, adding $\mathit{correction}$ leads to the need of tuning it, for which reason only the second approach is shown in the experiments in \vref{chap:experiments}.

        Therefore, another approach, replacing the explicit Euler from \vref{eq:euler}, is presented in \vref{eq:averaging}, that does spread the workload well and within only two iterations.
        \begin{equation}
        \label{eq:averaging}
            \mathit{old}_{e,i+1} = \frac{i \cdot \mathit{old}_{e,i} + \mathit{new}_{e,i}}{i+1}
        \end{equation}
        This result is treated as before, meaning Equations~\ref{eq:metric_cleanup} are also applied.
        From \vref{eq:averaging}, both $\mathit{old}_{e,1}=\mathit{new}_{e,0}$ and $\mathit{old}_{e,2}=\frac{\mathit{old}_{e,1} + \mathit{new}_{e,1}}{2}$ hold before normalization.
        The interpretation of these is quite intuitive.
        The first iteration favors popular routes.
        After the first update, the workload-metric is just the normalized workload from the original, unbalanced graph.
        Hence the following iteration has an aversion to popular routes and tends to avoid them.
        This second iteration favors alternative routes and the outcoming workload completes the previously generated workload-metric.
        A third iteration has already a workload-metric with a balance between popular and alternative routes, so further iterations appear disruptive.

\section{Details on implementation}
\label{chap:balancing:implementation}

    The implementation has the goal to be efficient, easy to use and maintainable.
    For this reason, some important decisions were made and the most important ones are explained (from a theoretical point of view) in the following.

    \subsection{Configuration-files}

        Main concept of the implementation is the use of configuration-files.
        The whole parser, simulation and computation can be adjusted with these files.
        One big advantage are the parser-related settings to define the graphs nodes and edges.
        Both meta-data and metric-data is defined in the configuration-file.
        This allows the graph to be static, meaning its allocated memory doesn't change during runtime after the graph is built and shrinked to fit its needs.
        However, its values can be changed, which is necessary, since the balancing updates a metric.

    \subsection{Storing and accessing graphs}
    \label{chap:balancing:implementation:graphs}

        The underlying graph-structure is implemented as adjacency-array with several extensions.
        The adjacency-array is explained in \cref{chap:preliminaries:graphs}.
        This data-structure fits well, because it reduces redundancy by optimizing the graph's memory-consumption.
        At the same time, accessing the graph can be done in constant or logarithmic time (depending on access via indices or via ids) through indexing-logic.
        The indexing-logic from adjacency-arrays has been extended by a mapping to support forward-, backward- and shortcut-edges in the graph, which is necessary for the bidirectional-Dijkstra.

        First, the graph from preliminaries is extended by metrics.
        For every edge in $E$, a vector of floats is stored.
        To formalize this, the cost-function is slightly redefined (and duplicated edges are being removed) to have edge-costs being associated as metrics.
        Let $C \subset E \times \mathbb{R}_+^d$ be the set of metrics and $c$ be the bijective function $c: E \to C$.
        With this definition, $C[i_E]$ can be associated as the cost-vector of the edge $E$ at edge-index $i_E$, where $C$ is stored as two-dimensional array of floats.

        The vertices $V$ are an array of vertex-ids sorted in ascending order.
        This is required by the adjacency-array, but also allows the search for nodes by their ids in logarithmic time.
        However, this is only needed for users outside the graph, because inside, the graph uses only vertex-indices.

        A backward-graph is a graph, whose edges are reversed according to the original graph.
        So a backward-graph maps edges $(s, d)$ to the reversed edge $(d, s)$.
        Since this graph is used for bidirectional routing-queries, it has to support the access to both forward-edges and backward-edges.
        The backward-edges could be stored accordingly to the forward-edges, meaning storing the source-indices $S$ in addition to the destination-indices $D$.
        The occuring issue with this is the sort-order of vertices $V$.
        All vertices are sorted by their source-id to match the offset-array $O_D$ for the forward-edges and for $D$.
        Respectively, all vertices should be sorted by their destination-id to match the offset-array $O_S$ for the backward-edges and for $S$.
        This would need a copy of all vertices and an edge-index $i_E$ wouldn't point to the same edge in $S$ and $D$, leading to two access-implementations doing basically the same offset-mapping.
        The metric-array $C$ could be accessed via $i_E$ only by Dijkstra's forward-search, not the backward-search, unless a mapping from backward-edge-indices to forward-edge-indices is built (or $C$ is also stored twice).
        Therefore, this issue is solved by using this very mapping, such that an edge-index $i_E$ belongs to $S[i_E]$, $D[i_E]$, $C[i_E]$ independent of the edge's orientation and the graph can be stored without data-redundancy.
        The decision towards no data-redundancy implies consistency, which is important for the metric-update.
        Further, it improves maintainability and usage, because accessing the forward-edges and backward-edges can be done with the same accessor simply using different arrays.
        The indices-mappings are illustrated in \cref{table:balancing:indices_mapping} and explained afterwards with two example-queries.
        The graph from \cref{chap:preliminaries:graphs} contains only bidirectional edges, thus the edge $(s, d)$ with $(V[s], V[d])=(1, 2)$ is removed to make the graph containing unidirectional edges.

        \begin{table}[htbp]
            \centering
            \begin{tabular}{ l || c | c c | c c c | c c c | c c | c }
                $i_E = i_\mathit{fwd}$ & \multicolumn{12}{c}{Storing data with respect to forward-edges} \\
                \hline
                \hline
                $V$ & $\mathit{id}_0$ & \multicolumn{2}{c |}{$\mathit{id}_1$} & \multicolumn{3}{c |}{$\mathit{id}_2$} & \multicolumn{3}{c |}{$\mathit{id}_3$} & \multicolumn{2}{c |}{\cellcolor[gray]{0.8} $\mathit{id}_4$} & - \\
                \hline
                $S$ & \cellcolor[gray]{0.8} 0 & 1 & 1 & \cellcolor[gray]{0.8} 2 & 2 & 2 & \cellcolor[gray]{0.8} 3 & 3 & 3 & 4 & 4 & - \\
                $D$ & 1 & 0 & 3 & 1 & 3 & 4 & 1 & 2 & 4 & \cellcolor[gray]{0.8} 2 & \cellcolor[gray]{0.8} 3 & - \\
                $C$ & a & b & c & d & e & f & g & h & i & j & k & - \\
                & & & & & & & & & & & & \\
                $i_\mathit{fwd}$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & \cellcolor[gray]{0.8} 9 & \cellcolor[gray]{0.8} 10 & - \\
                $\mathit{map}_\mathit{bwd}: i_\mathit{fwd} \mapsto i_\mathit{bwd}$ & 1 & 0 & 6 & 2 & 7 & 9 & 3 & 4 & 10 & 5 & 8 & - \\
                & & & & & & & & & & & & \\
                $O_D: i_V \mapsto i_\mathit{fwd}$ & 0 & \multicolumn{2}{c |}{1} & \multicolumn{3}{c |}{3} & \multicolumn{3}{c |}{6} & \multicolumn{2}{c |}{\cellcolor[gray]{0.8} 9} & \cellcolor[gray]{0.8} 11 \\
                \multicolumn{13}{c}{} \\
            \end{tabular}
            \begin{tabular}{ l || c | c c c | c c | c c c | c c | c }
                $i_E = i_\mathit{bwd}$ & \multicolumn{12}{c}{Storing data with respect to backward-edges} \\
                \hline
                \hline
                $V$ & $\mathit{id}_0$ & \multicolumn{3}{c |}{\cellcolor[gray]{0.8} $\mathit{id}_1$} & \multicolumn{2}{c |}{$\mathit{id}_2$} & \multicolumn{3}{c |}{$\mathit{id}_3$} & \multicolumn{2}{c |}{$\mathit{id}_4$} & - \\
                \hline
                $D_\mathit{bwd}$ & 0 & 1 & 1 & 1 & 2 & 2 & 3 & 3 & 3 & 4 & 4 & - \\
                $S_\mathit{bwd}$ & 1 & 0 & 2 & 3 & 3 & 4 & 1 & 2 & 4 & 2 & 3 & - \\
                $C_\mathit{bwd}$ & b & a & d & g & h & j & c & e & k & f & i & - \\
                & & & & & & & & & & & & \\
                $\mathit{map}_\mathit{fwd}: i_\mathit{bwd} \mapsto i_\mathit{fwd}$ & 1 & \cellcolor[gray]{0.8} 0 & \cellcolor[gray]{0.8} 3 & \cellcolor[gray]{0.8} 6 & 7 & 9 & 2 & 4 & 10 & 5 & 8 & - \\
                $i_\mathit{bwd}$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & - \\
                & & & & & & & & & & & & \\
                $O_S: i_V \mapsto i_\mathit{bwd}$ & 0 & \multicolumn{3}{c |}{\cellcolor[gray]{0.8} 1} & \multicolumn{2}{c |}{\cellcolor[gray]{0.8} 4} & \multicolumn{3}{c |}{6} & \multicolumn{2}{c |}{9} & 11 \\
            \end{tabular}
            \caption[Indices-mapping for accessing graph-data via offset-arrays]{%
                This table shows one graph stored with respect to forward-edges above and with respect to backward-edges below.
                Note that a backward-graph of a graph has just the edges being reversed, so $(s, d) \mapsto (d, s)$.
                The more intuitive way is storing the graph and necessary indices forwardly.
                That's why the forward graph's notation is used as default (\eg\ $S$ is used instead of $S_\mathit{fwd}$ according to $S_\mathit{bwd}$).
                However, both offset-arrays $O_D$ and $O_S$ and $\mathit{map}_\mathit{fwd}$ are needed and hence each table is needed.

                The tables highlight important values of the two example-queries from the text.
                \label{table:balancing:indices_mapping}
            }
        \end{table}

        Two example-queries are explained in the following, assuming the graph being stored with respect to forward edges.
        In general, leaving edges of vertex $V[s]$ or incoming edges of a vertex $V[d]$ can be determined by following mappings (referring to \cref{table:balancing:indices_mapping}):
        \begin{equation}
        \label{eq:balancing:indices_mapping}
        \begin{aligned}
            \mathit{offset} &\in \left\{ O_D \left[ s \right], O_D \left[ s \right] + 1, \dots, O_D \left[ s+1 \right] - 1 \right\} \\
            d_\mathit{offset} &= D \left[ \mathit{identity}_\mathit{fwd} \left[ \mathit{offset} \right] \right] \\
            s &\mapsto \left\{ \left( s, d_\mathit{offset} \right) \right\} \\
            \\
            \mathit{offset} &\in \left\{ O_S \left[ d \right], O_S \left[ d \right] + 1, \dots, O_S \left[ d+1 \right] - 1 \right\} \\
            s_\mathit{offset} &= S \left[ \mathit{map}_\mathit{fwd} \left[ \mathit{offset} \right] \right] \\
            d &\mapsto \left\{ \left( s_\mathit{offset}, d \right) \right\} \\
        \end{aligned}
        \end{equation}
        The mapping $\mathit{map}_\mathit{fwd}$ can be computed by sorting all edges according to the forward-graph (first source-id, than destination-id) before sorting all edges again according to the backward-graph (first destination-id, than source-id).
        In between, the edge-positions from the first sorted edges are linked to the edges, such that they get reordered by sorting a second time.
        After sorting the second time, the remembered positions become the mapping $\mathit{map}_\mathit{fwd}$.

        In the examples, one query is asking for all leaving edges starting in $V[s=4]=\mathit{id}_4$ and one is asking for all incoming edges ending in $V[d=1]=\mathit{id}_1$.
        The choice of $d=1$ is handy, because $(2, 1) \in E \wedge (1, 2) \notin E$ holds, which might help with understanding the examples.
        Important values in these examples are highlighted in the tables.

        To get all leaving edges starting in $V[s=4]=\mathit{id}_4$, the offset-array $O_D$ is used.
        All forward-indices within $\left\{ O_D[s], O_D[s] + 1, \dots, O_D[s+1] - 1 \right\}$ refer to the leaving edges.
        Since $O_D[4]=9$ and $O_D[5]=11$, all leaving-edges are at positions $\left\{ 9, 10 \right\}$ with respect to forward-edges.
        Because the graph is stored with respect to forward-edges, these resulting positions are already the edge-indices $i_E$ of the leaving-edges.
        The \cref{table:balancing:indices_mapping} still marks the respective values \num{9} and \num{10} in the forward-table.
        Thus, all leaving-edges are $\left\{ (4, D[9]=2), (4, D[10]=3) \right\} = \left\{ (4,2), (4,3) \right\}$.

        Getting all incoming edges ending in $V[d=1]=\mathit{id}_1$ works similar and uses the offset-array $O_S$ respectively.
        All backward-indices within $\left\{ O_S[d], O_S[d] + 1, \dots, O_S[d+1] - 1 \right\}$ refer to the incoming edges.
        The difference here is the outcome from $O_S$.
        Due to $O_S[1]=1$ and $O_S[2]=4$, all incoming-edges are at positions $\left\{ 1, 2, 3 \right\}$ with respect to backward-edges, but the graph is stored with respect to forward-edges.
        Therefore, the indices are not matching and the resulting positions $\left\{ 1, 2, 3 \right\}$ need to be mapped to the respective (forward-) edge-indices $i_E$.
        For this, $\mathit{map}_\mathit{fwd}$ is used.
        \begin{equation}
        \begin{aligned}
            \mathit{map}_\mathit{fwd}[1] &= 0 \Rightarrow S[0] = 0 \\
            \mathit{map}_\mathit{fwd}[2] &= 3 \Rightarrow S[3] = 2 \\
            \mathit{map}_\mathit{fwd}[3] &= 6 \Rightarrow S[6] = 3 \\
        \end{aligned}
        \end{equation}
        Thus, all incoming-edges are $\left\{ (0, 1), (2, 1), (3, 1) \right\}$.

    \subsection{Storing and accessing shortcuts in graphs}

        Shortcuts have metrics and source-/destination-vertices as well, so they are full edges and can be added to the current data-structure.
        However, due to construction of a contracted graph, a shortcut replaces two edges, which may be shortcuts.
        This functionality is missing in the graph's data-structure yet.
        A first intuition may be extending edges by a tuple of two edge-indices.
        Implementing this causes much redundancy, because normal edges would need a placeholder for their tuple.
        The street-networks from the experiments in \cref{chap:experiments} have less than $|E|$ shortcuts added.
        So after adding all shortcuts, more than half of all edges will have unused allocated memory of two indices.
        For example, Saarland from the experiments contains over $\num{1000000}$~edges.
        If these placeholders would be used, each of these million edges would have two unused indices.
        Assuming one index needs $\si{\num{64} \bit}$, this sums up to $\si{\num{16} \mega\byte}$ of unused memory.
        This number scales with the graph's size, so Germany with over $\num{100000000}$~edges would have already $\si{\num{1.6} \giga\byte}$ of completely unused, but allocated memory.

        Therefore, since edge-indices $i_E$ can be used for all edge-data ($S$, $D$, $C$), this whole indexing-procedure from \cref{chap:balancing:implementation:graphs} can be and is used in this thesis for storing and accessing shortcuts without such placeholders.
        Like the offsets $O_D$ and $O_S$, another offset-array is created.
        Let this new offset-array be called $O_L$ ($L$ for link, since $S$ is already used).
        The significant difference between $O_D$ and $O_S$ on one side and $O_L$ on the other side is, that $O_L$ contains an offset-value per edge, whereas $O_D$ and $O_S$ contain offset-values per vertex.
        Lining all shortcut-tuples of edge-indices up according to the forward-edges' order in the graph, this results in the data-array $L$.
        This array $L$ behaves exactly similar as the array $S$ or $D$.
        So, despite the indexing-mapping, the shortcut-indices of an edge-index $i_E$ can be found in $L$ between $O_L \left[ i_E \right]$ (including) and $O_L \left[ i_E + 1 \right]$ (excluding).
        A shortcut can be determined by comparing neighbouring values in $O_L$.
        If $O_L \left[ i_E \right] = O_L \left[ i_E + 1 \right]$ holds, the edge at $i_E$ is no shortcut.

        When analyzing the memory-usage, this method has improved the other approach of storing tuples in the experiments.
        Let $m$ be the number of edges without shortcuts and $m_L$ the number of shortcuts in the graph.
        Previously, the number of needed indices was $2 \cdot (m + m_L)$.
        The offset-procedure stores $2 \cdot m_L$ replaced edge-indices and $(m + m_L)$ offset-indices, resulting in $m + m_L + 2 \cdot m_L$.
        As long as $m_L < m$ holds, the offset-procedure saves memory, which was the case in all experimental graphs.

    \subsection{Multithreading}

        The implementation of searching for paths in parallel has brought a huge performance-boost.
        Optimal paths of different \glspl{stpair} may have different costs and thus need a different amount of runtime.
        This holds especially for \gls{repr}, where longer paths lead to more alternative paths.
        Therefore, the number of \glspl{stpair} is not distributed evenly over all threads.
        In fact, there is one single master-thread pulling some \glspl{stpair} from the user-provided set of \glspl{stpair} and sends this work-package to one of several worker-threads.
        Every worker-thread has its own instance of the routing-algorithm, searches for the optimum paths, and returns a simple list of all occurred edge-indices $i_E$ to the master-thread.
        The master-thread counts the workloads for each edge and pulls the next work-package until all \glspl{stpair} are processed.

        With this procedure, the workload and not the number of \glspl{stpair} is distributed evenly.
        The communication-overhead when using smaller work-package-sizes is negligible compared to idle worker-threads, that wait for the last few worker-threads to finish their larger work-package.