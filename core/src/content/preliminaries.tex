\chapter{Preliminaries}
\label{chap:preliminaries}

The creation of a new metric is basically done by a chain of methods, that is looped to update the metric.
This chapter introduces these methods and explains them briefly.

\section{Graphs stored as adjacency-array}
\label{chap:preliminaries:graphs}

    Let a street-network be given as a graph $G = (V, E)$ with vertices $V$ (also called nodes), edges $E$ and a cost-function $c: E \to \mathbb{R}_+^d$, that returns a cost-vector for each edge $e \in E$, also called multidimensional metrics in this thesis.
    Metrics are also called costs depending on the context.

    For the theory of this thesis, above definitions are sufficient.
    However, the implementation-details in \cref{chap:balancing:implementation} concretize the graph's definition to store the graph efficiently.
    The underlying graph's data-structure is based on the idea of adjacency-arrays, which is mentioned in~\cite{mehlhorn:algorithms}.
    For this reason, this brief idea is extended both in the following to demonstrate the brief idea and in \cref{chap:balancing:implementation}.
    Before the adjacency-array can be concretized, the graph has to be slightly redefined, so it can be referred with arrays and indices.

    Since $V$ and $E$ are finite, let $n := \left| V \right|$ be the number of vertices and $m := \left| E \right|$ be the number of edges.
    Then, the graph's components are interpreted and stored as follows.
    \begin{itemize}
        \item[Vertices:]
            For implementation, vertices in $V$ are just ids, which are stored in an array in ascending order.
            The order is needed for accessing the graph's data later.
            So let $V$ be an array of node-ids and $V[i_V]$ be the node-id at node-index $0 \le i_V < n$.
        \item[Edges:]
            Edges are considered to be directed and $E$ is defined as an array of tuples of two vertex-indices, so $E \subseteq \left\{ 0, 1, \dots, n-1 \right\}^2$.
            However, the sources and destinations in $E$ are stored in separate arrays, so $E := (S, D)$ and $E[i_E] = (S[i_E], D[i_E])$ is the edge from source-index in $S$ at edge-index $i_E$ to destination-index in $D$ at edge-index $i_E$.
            Since the graph is stored as adjacency-array, $E$ is considered to be sorted by source-, then by destination-id (although vertex-indices are stored in $S$ and $D$), in ascending order.
            Let the respective offset-array for remaining $D$ be $O_D$.
            The creation and use of $O_D$ is explained below.
            With the interpretation of the offset-array, storing $S$ will not be necessary, because $S$ (without duplicates) will be $[0, 1, \dots, n-1]$ and thus match $V$.
    \end{itemize}

    After these definitions, the core of the adjacency-array is basically the creation of the offset-array $O_D$, which then helps accessing the graph's components in constant time.
    For every vertex $v \in V$, the offset-array $O_D$ stores the edge-index $i_E$, where the leaving edges starting in $v$ occur.
    Since $V$ is sorted by source-id first, all these leaving edges will be grouped in $O_D$ (and $D$).
    Here, the sorted $E$ is needed.
    This is demonstrated in \cref{table:preliminaries:offset-array} and explained below.

    \begin{table}[htbp]
        \centering
        \begin{tabular}{ l || c | c c c | c c c | c c c | c c | c }
            Vertices $V$ ($\sim$ sources $S$) & $\mathit{id}_0$ & \multicolumn{3}{c |}{$\mathit{id}_1$} & \multicolumn{3}{c |}{$\mathit{id}_2$} & \multicolumn{3}{c |}{$\mathit{id}_3$} & \multicolumn{2}{c |}{$\mathit{id}_4$} & - \\
            \hline
            Destinations $D$ & 1 & 0 & 2 & 3 & 1 & 3 & 4 & 1 & 2 & 4 & 2 & 3 & - \\
            Offsets $O_D$ & 0 & \multicolumn{3}{c |}{1} & \multicolumn{3}{c |}{4} & \multicolumn{3}{c |}{7} & \multicolumn{2}{c |}{10} & 12 \\
        \end{tabular}
        \caption[Small example-graph stored as adjacency-array]{%
            A graph with $|V| = 5$ and $|E| = 12$ stored as adjacency-array, shown with the respective offset-array.
            Every edge in the graph is bidirectional, but stored directed and represents as a tuple of source- and destination-vertex.
            All destinations of leaving edges starting in $V[s=3] = \mathit{id}_3$ are in $D$ between positions $O_D[s] = 7$ (including) and $O_D[s+1] = 10$ (excluding).
            \label{table:preliminaries:offset-array}
        }
    \end{table}

    Let $e = E[i_E] = (S[i_E], D[i_E]) = (s, d)$ be an edge at position $i_E$ and $s$ be the position of the edge's source in $V$.
    Because the edges are sorted by source, than by destination, all edges starting in $V[s]$ are in $D$ between positions $O_D[s]$ (including) and $O_D[s+1]$ (excluding).
    Since every edge-data can be stored according to the edges' destinations $D$ (like metrics), this allows quick access to all relevant edge-components by simply providing the edge-index while keeping the memory-usage low.
    Besides that, it can be extended quite easily and complex, as it is done in \cref{chap:balancing:implementation}.

\section{Contraction-hierarchies}

    This thesis uses sets of many \glspl{stpair} to search for optimum paths.
    These paths are used to optimize routing-algorithms for the underlying street-network.
    In fact, the largest bottleneck of the whole thesis is the search for optimum paths.
    This also offers the opportunity to improve the performance.
    One approach to do this is the reduction of the search-space and a method called contraction-hierarchies is used for this purpose.
    The algorithm is divided into a preprocessing and the actual user-provided query.
    The first is explained here, the latter in \cref{chap:preliminaries:ch-dijkstra}.

    The preprocessing phase iterates over all vertices in a graph and contracts them.
    The contraction basically removes each vertex $v \in V$ from the graph.
    Every shortest path from a neighbouring vertex of $v$ to a neighbouring vertex of $v$, that is the only shortest path between these respective neighbours and that needs $v$ to exist, is replaced by a new edge between the respective neighbours.
    This new edge is called shortcut and represents the shortest path by adapting its weights.
    Additionally, levels ($\in \mathbb{N}$) are assigned to every vertex, and the levels increase with the iteration-progress.
    These levels are considered in the query to reduce the search-space.

    The quality of the contracted graph (and the query-time with it) highly depends on the contraction-order.
    If too many shortcuts have to be added with a vertex-contraction, the graph gets more verbose.
    For this reason, different criteria for good vertices are applied, \eg\ considering the number of created shortcuts and the removed edges or whether a neighbour of a vertex has just been contracted.

    This thesis deals with multidimensional metrics.
    Because of this, the insertion of a new shortcut needs to be redefined.
    If any $\alpha$ exists, such that the only optimum path with respect to minimum $\sum_{i=1}^{d} \alpha_i \cdot c_i(\mathit{path})$ needs the contracted vertex $v$, then a shortcut is added.
    The challenge here is to explorate the set of possible $\alpha$ efficiently.
    \cite{funke:personal-routes} provides an approach using linear programming using Dijkstra as separation-oracle.
    A linear program solves an optimization-problem in finite many variables, where a linear objective function is optimized under a finite number of linear equality or inequality constraints.
    A separation-oracle helps in discarding non-optimal solutions more efficiently.

\section{Dijkstra's algorithm (bidirectional) in contracted graphs}
\label{chap:preliminaries:ch-dijkstra}

    An unidirectional Dijkstra (introduced in \cite{dijkstra:dijkstra}) computes an optimum path for a provided \gls{stpair} in a graph with only one metric.
    It assigns the weight of zero to $s \in V$, marks $s$ as visited and goes through all neighbours $v \in V$ of $s$ to update their path-cost, that belongs to the path of minimum cost from $s$ to $v$ so far.
    Then, every neighbour of $s$ is pushed to a priority-queue, except for those, that have already been visited (which is only $s$ in this first iteration).
    In the next step, the vertex of minimum cost in the priority-queue is pulled from the queue and marked as visited.
    It updates its neighbours' optimum paths' cost and all neighbours, that improve their cost by using $v$, are pushed into the priority-queue.
    Note, that a node can be enqueued multiple times with different costs.
    This procedure stops as soon as $t \in V$ is pulled from the priority-queue.
    The optimum path can be constructed by remembering predecessors during the visit-phase.

    To reduce the search-space of Dijkstra, it can be modified to search from both $s$ and from $t$ towards each other, which is called bidirectional Dijkstra.
    Pushing vertices to a common priority-queue, while vertices remember their search-direction (forwards from $s$ or backwards from $t$), can be used to balance both sub-queries.
    As soon as a vertex is visited by both sub-queries, no more neighbours need to be enqueued.
    This vertex, that is visited by both sub-queries, is called meeting-vertex.
    If the best meeting-vertex has better total costs than all vertices $v$ remaining in the queue, the query stops.
    The optimum path can be constructed from the meeting-vertex, similar to unidirectional Dijkstra, by remembering predecessors and successors during the visit-phase.

    When doing bidirectional Dijkstra with contracted graphs, some adjustments are required.
    To reduce the search-space, only neighbours of dequeued vertices are considered, that have at least the assigned level of $v$.
    Typically, neighbouring vertices don't have common levels, but the contraction may be stopped before all vertices are contracted.
    This speeds the query up significantly.
    However, it also causes the sub-queries to search in different sub-graphs.
    The sub-queries in bidirectional Dijkstra search in the same sub-graphs.
    That leads to the issue, that found optimum paths of a sub-query are not necessary optimal for the whole query.
    To fix this, just keep on enqueuing neighbours even when a meeting-vertex is already found.
    As soon, as the best meeting-vertex has better total costs than all vertices remaining in the queue, the query stops.

    The optimum path can be constructed as in the case of bidirectional Dijkstra.
    Of course, this optimum path might contain shortcut-edges, but these can be replaced by the original edges recursively.

\section{(Restricted) Enumerating personalized routing}

    Personalized routing is basically applying a preference-vector $\alpha$ to reduce the multidimensional costs to one scalar by computing the dot-product of $\alpha$ and the respective cost-vector.
    Dijkstra can be adjusted to compute the optimum path considering a user-provided $\alpha$.
    Instead of computing paths' costs for one metric, they are computed for the $\alpha$-dependent dot-product.

    Interpreting a path's cost as point in the $d$-dimensional cost-space, the dot-product with a vector $\alpha$ can be seen as the projection of the path's cost-vector onto the chosen vector $\alpha$.
    In other words, Dijkstra is searching for the minimum dot-product, hence the projection onto $\alpha$ of minimum length.
    Thus, Dijkstra finds extrema of the convex hull of all existing paths for a given \gls{stpair} in the underlying $d$-dimensional cost-space.

    This is used in~\cite{barth:alternative_multicriteria_routes} to develop an algorithm enumerating this convex hull's extrema.
    An initial convex hull in the $d$-dimensional cost-space contains several $(d-1)$-dimensional simplexes (\eg\ triangles in 3D).
    In \cref{chap:balancing:balancing}, it is explained and adjusted, how such an initial convex hull can be found.
    Each simplex has a normal-vector, which can be computed by a $d$-dimensional linear-equation-system.
    Since simplexes are only $(d-1)$-dimensional, the length of the resulting normal-vector is arbitrary.
    To fix this, the last equation in the system forces the sum of all entries in the normal-vector to be $1$.
    It occurs, that this normal-vector can be interpreted as $\alpha$-vector, which leads to identical costs for all paths being involved in the simplex.
    Now, if Dijkstra finds a path with this $\alpha$, that is not part of the simplex, this path must be better than every path of the simplex (with respect to this particular $\alpha$) and thus must be another extremum of the convex hull.
    Adding the new found path to the convex hull brings new simplexes up, that can be treated as already described, possibly resulting in new paths for the found convex hull.

    This method stops as soon as no new paths has been found and is called \glsreset{epr}.

    When using initial $\alpha$-vectors preferring only one metric, the resulting path is the optimum path over all $\alpha$ with respect to this very metric.
    With this, a tolerance can be defined, that describes the accepted maximum relative difference between this optimum path and any other path, that is found.
    \cite{barth:alternative_routes} improves this enumeration in its runtime by discarding simplexes, where all paths have at least one metric, where no path can beat the tolerance.
    This allows to discard the simplex and reduces the search-space, thus runtime.
    The resulting method is a slightly changed version of \glsreset{epr}\gls{epr} and is called \glsreset{repr}\gls{repr}.
    It is used in this thesis to find multiple alternative paths.